---
layout: post
title: 동시성과 병렬 처리
tags: [운영체제, 동시성과 병렬 처리]
categories: [운영체제, 동시성과 병렬 처리]
image:
  path: /assets/img/post/operating-system/concurrency.png
  alt: concurrency
date: 2023-12-20 14:46 +0900
---

## 동시성과 병렬 처리

운영체제에서의 동시성(Concurrency)과 병렬 처리(Parallel Processing)는 현대 컴퓨팅 시스템의 핵심 기능이다. <br>
이들은 **효율적인 시스템 성능과 자원 활용**을 위해 중요한 역할을 한다. 두 개념은 서로 관련이 있지만, 명확히 구분되어야 한다.

### 동시성 (Concurrency)

동시성은 **여러 작업이 시간상으로 겹쳐 실행되는 것**을 의미한다.

- **작업의 중첩**: 여러 프로세스나 스레드가 '동시에' 실행되는 것처럼 보인다. **실제로는 시분할(time-sharing) 방식으로 CPU가 빠르게 여러 작업 사이를 전환**한다. 🫢
- **자원 공유**: 동시에 실행되는 프로세스나 스레드는 시스템 자원(메모리, 파일 등)을 공유한다.
- **컨텍스트 스위칭**: CPU는 **한 작업에서 다른 작업으로 전환할 때 현재 상태(컨텍스트)를 저장하고, 새 작업을 불러온다**.
- **동시성 문제**: 데이터 일관성과 무결성을 유지하기 위해 동기화 메커니즘(뮤텍스, 세마포어 등)이 필요하다.

### 병렬 처리 (Parallel Processing)

병렬 처리는 **여러 처리 단위가 동시에 서로 다른 작업을 수행하는 것**을 말합니다.

- **다중 처리 장치**: 멀티코어 프로세서나 여러 프로세서를 사용하여 다양한 작업을 동시에 수행한다.
- **데이터 분할**: **큰 문제를 작은 부분으로 나누어** 각 코어나 프로세서가 동시에 다룰 수 있다.
- **효율성 증가**: 병렬 처리를 통해 더 많은 작업을 더 빠르게 처리할 수 있어, 계산 효율성이 증가한다.

![concurrency-and-parallel](/assets/img/post/operating-system/concurrency-and-parallel.jpeg){: width="500" }

> 동시성과 병렬처리를 위해 운영체제의 역할은 과연 무엇일까? 🧐

### 운영체제의 역할

- **스케줄링**: CPU와 자원을 효율적으로 할당하고 관리한다.
- **동기화**: 공유 자원에 대한 접근을 제어하여 데이터의 일관성과 무결성을 보장한다.
- **교착 상태 관리**: 여러 프로세스가 동시에 같은 자원을 요청할 때 발생할 수 있는 교착 상태를 감지하고 해결한다.
- **자원 관리**: 메모리, 입출력 장치 등의 자원을 효율적으로 관리한다.

#### 동시성 및 병렬처리 주요 개념

- **데드락 (Deadlock)**: 데드락은 **여러 프로세스나 스레드가 서로의 작업 완료를 무한히 기다리는 상태**를 말한다.
  - **발생 조건(4가지 조건이 모두 해당할 경우 발생)**
    - **상호 배제(Mutual Exclusion)**: 자원은 한 번에 하나의 프로세스만 사용할 수 있다.
    - **보유 및 대기(Hold and Wait)**: 프로세스가 자원을 보유한 채로 다른 자원을 기다린다.
    - **비선점(No Preemption)**: 자원은 사용 중인 프로세스에 의해 자발적으로만 방출될 수 있다.
    - **순환 대기(Circular Wait)**: 프로세스 간에 순환적으로 자원을 기다리는 현상.
  - **해결 방법**
    - **데드락 예방(Prevention)**
      - **설명**: 위 네 조건 중 하나 이상을 무력화시키는 전략
      - **예시**
        - **비선점(No Preemption) 조건**: 자원이 선점할 수 있도록 만들어, 다른 프로세스가 필요할 때 해당 자원을 빼앗을 수 있도록 한다.
        - **순환 대기(Circular Wait) 조건**: 자원에 일련번호를 부여하고, 프로세스가 오름차순으로만 자원을 요청하게 함으로써 이 조건을 제거할 수 있다.
    - **데드락 회피(Avoidance)**
      - 설명: 자원 할당 시 데드락의 가능성을 고려하여 회피
      - **예시**
        - **은행원 알고리즘(Banker's Algorithm)**: 프로세스가 **최대로 요구할 수 있는 자원을 미리 알고**, 시스템이 안전 상태(각 프로세스가 요구한 양만큼 자원을 할당해 줄 수 있는 상태)에 있을 때만 자원을 할당한다.
    - 데드락 검출 및 복구(Detection and Recovery)
      - **데드락 탐지**: 주기적으로 또는 특정 이벤트가 발생했을 때 데드락 탐지 알고리즘을 실행한다. 자원 할당 그래프 등을 사용하여 데드락을 탐지한다.
      - **회복**: 데드락이 탐지되면, 프로세스를 종료하거나 할당된 자원을 선점하여 데드락을 해결한다.

![deadlock](/assets/img/post/operating-system/deadlock.jpg){: width="600" }

- **뮤텍스(Mutex, Mutual Exclusion Object)**
  - **설명**: 동시성 프로그래밍에서 중요한 동기화 메커니즘으로, 이는 **여러 스레드나 프로세스가 공유 자원에 동시에 접근하는 것을 방지**하여, 데이터의 일관성과 무결성을 유지하는 데 사용된다.
  - **뮤텍스의 기본 원리**
    - **임계 영역 (Critical Section)**: 공유 자원에 접근하는 코드 영역이다. 한 번에 한 스레드만 접근할 수 있다.
    - **상호 배제 (Mutual Exclusion)**: 뮤텍스는 한 시점에 하나의 스레드만이 임계 영역에 접근할 수 있도록 보장한다. 이를 통해 동시에 같은 자원에 접근하는 것을 방지한다.
  - **뮤텍스의 작동 방식**
    - **잠금 (Locking)**: **스레드가 임계 영역에 진입하기 전에 뮤텍스를 '잠그고(lock)' 들어간다**. 이는 다른 스레드가 해당 임계 영역에 접근하는 것을 방지한다.
    - **해제 (Unlocking)**: **스레드가 임계 영역의 작업을 마치면 뮤텍스를 '해제(unlock)'한다**. 이로써 다른 스레드가 임계 영역에 접근할 수 있게 된다.

![mutex](/assets/img/post/operating-system/mutex.jpg){: width="800" }

- **세마포어(Semaphore)**
  - **설명**: **복수의 프로세스나 스레드가 공유 자원에 접근할 때 발생할 수 있는 동시성 문제를 해결**하기 위한 동기화 메커니즘으로, 세마포어는 기본적으로 정숫값을 가진 변수로, 공유 자원에 대한 접근을 제어하는 데 사용된다.
  - **세마포어의 기본 원리**
    - **정수 변수**: 세마포어는 정숫값을 가지며, 이 값은 **공유 자원에 접근할 수 있는 허용 가능한 최대 프로세스 또는 스레드의 수**를 나타낸다.
    - **P 연산 (Wait, Down, Decrement)**: 세마포어의 값을 감소시키는 연산이다. 값이 0보다 크면, 세마포어는 감소하고 프로세스는 진행된다. 만약 세마포어가 0이면, 프로세스는 대기 상태로 들어간다.
    - **V 연산 (Signal, Up, Increment)**: 세마포어의 값을 증가시키는 연산이다. 대기 중인 프로세스가 있다면, 하나의 프로세스가 깨어나 작업을 계속할 수 있다.

![semaphore](/assets/img/post/operating-system/semaphore.png){: width="600" }

- **병렬 컴퓨팅**
  - **설명**: **여러 처리 장치(CPU 코어, 프로세서, 컴퓨터 등)가 동시에 여러 계산 작업을 수행**하는 컴퓨팅 기법이다.
  - **병렬 컴퓨팅의 주요 개념**
    - **병렬화 (Parallelization)**: 작업을 여러 하위 작업으로 분할하여 동시에 수행한다.
    - **스케일링 (Scaling)**: 병렬 컴퓨팅은 시스템의 성능을 확장하거나 축소할 수 있도록 한다. (스케일 업/스케일 아웃)
      ![scale-up-and-down](/assets/img/post/operating-system/scale-up-and-down.webp){: width="600" }
    - **부하 분산 (Load Balancing)**: 작업을 여러 프로세서에 고르게 분배하여 효율적인 실행을 달성한다.
  - **병렬 컴퓨팅의 종류**
    - **데이터 병렬성 (Data Parallelism)**: **동일한 연산을 서로 다른 데이터 세트에 동시에 적용**한다. 예를 들어, 벡터 연산이나 대규모 배열 처리에서 사용된다.
    - **작업 병렬성 (Task Parallelism)**: 각 프로세스(또는 스레드)는 서로 다른 작업을 동시에 수행한다.

![data-and-task-parallelism](/assets/img/post/operating-system/data-and-task-parallelism.jpeg){: width="600" }
